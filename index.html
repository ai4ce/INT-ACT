<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models">
  <meta name="keywords" content="Tactile Sensing, 3D Gaussian, Sparse-View Reconstruction">     
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script> -->
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/copy2clipboard.js"></script>
  <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
  
  <script src="https://cdn.knightlab.com/libs/juxtapose/latest/js/juxtapose.min.js"></script>
  <link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css">
</head>


<body>

<!-- Navigation bar. -->
<nav class="navbar is-light" role="navigation" aria-label="main navigation">
  <div class="container is-max-desktop">

    <!-- Lab logo. Will stay here even if view from mobile -->
    <div class="navbar-brand">
      <a class="navbar-item" href="https://ai4ce.github.io/" target="_blank" rel="noopener noreferrer">
        <img src="./static/images/ai4ce_new_linear_notext.svg" alt="AI4CE Lab" style="height: 2.0rem;">
      </a>
      <a role="button" onclick="this.classList.toggle('is-active');document.querySelector('#'+this.dataset.target).classList.toggle('is-active');" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbarBasicExample">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>

    <!-- Will collapse into a "burger" menu on mobile. -->
    <div id="navbarBasicExample" class="navbar-menu">

      <div class="navbar-start">
        <a class="navbar-item" href="https://www.nyu.edu/" target="_blank">
          <img src="./static/images/NYU_Long_RGB_Color.png" alt="NYU Logo" style="height: 2.0rem;">
        </a>
      </div>
      

      <div class="navbar-end">
        <!-- After accepted, add conference logo here -->
        <!-- <a class="navbar-item" href="https://cvpr.thecvf.com/Conferences/2024" target="_blank" rel="noopener noreferrer">
            <img src="img/logo/logo-cvpr.png" alt="CVPR 2024" style="height: 2.0rem;">
        </a> -->

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://ai4ce.github.io/SeeDo/">
              SeeDo
            </a>
            <a class="navbar-item" href="https://ai4ce.github.io/FusionSense/">
              FusionSense
            </a>
          </div>
        </div>

      </div>
      
    </div>

  </div>
</nav>

<!-- Title and authors. -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            From Intention to Execution
          </h1>
          <h1 class="title is-2 publication-title">Probing the Generalization Boundaries of Vision-Language-Action Models</h1>
          <!-- <div class="column is-full_width">
            <h2 class="title is-4"><a href="https://2025.ieee-icra.org">ICRA 2025 (Under Review)</a></h2>
          </div> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://irvingf7.github.io/">Irving Fang*</a>,</span>
            <span class="author-block">
              <a href="https://juexzz.github.io/">Juexiao Zhang*†</a>,</span>
            <span class="author-block">
              <a href="https://tsb0601.github.io/">Shengbang Tong</a>, </span>
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=YeG8ZM0AAAAJ">Chen Feng</a></span>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"> New York University </span>
            <br>
            <span class="author-block"><sup>*</sup> Equal Contribution, <sup>†</sup> Project Lead </span>
          </div>



          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                 <!-- add here later. -->
                <a href="http://arxiv.org/abs/2506.09930"                
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- <span class="link-block"> -->
                <!-- add here later. -->
               <!-- <a href=""                    
                  class="external-link button is-normal is-rounded is-dark">
                 <span class="icon">
                     <i class="fas fa-camera"></i>
                 </span>
                 <span>Appendix</span>
               </a> -->
             <!-- </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://youtu.be/thC0PeAQxe0"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ai4ce/INT-ACT"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://huggingface.co/datasets/ai4ce/EgoPAT3Dv2"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser. -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width teaser no-margin">
        
        <h2 class="title is-3">TLDR</h2>
        <p style="font-size: 20px; background-color: #8b00e13b;">
          1. <b>INT-ACT</b>: <b>probing suite</b> to evaluate the generalization capability of robotic VLAs.
          <br>
          2. Benchmarking SOTA VLAs to understand their <b>generalization boundaries</b>.
        </p>
      </div>
  </div>
    <!-- add image here later -->
  <div class="column is-full-width teaser no-margin">
    <img src="./static/images/teaser.gif" alt="Teaser Image" style="width: 100%; max-width: 800px; height: auto;">
  </div>
</section>

<hr>


<!-- Categories -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">INT-ACT Categories</h2>
        <center>
          <!-- This image is always visible  -->
          <p>
            INT-ACT is a probing suite to evaluate the generalization capability of robotic VLAs. 
            It consists of <b>three</b> categories of tasks that probe the generalization boundaries of VLAs.
            <br>
            <br>
            <b>Object Diversity:</b> Ability to handle out-of-distribution objects.
            <br>
            <b>Language Complexity:</b> Ability to understand complex language instructions.
            <br>
            <b>Vision-Language Thinking:</b> Ability to perform commonsense reasoning and visual-language thinking.
          </p>
          <div id="overview">
            <img src="./static/images/task_distribution.svg" style="width: 40vw; min-width: 330px;" alt="Overview Image"> 
          </div>

          <!-- Here, the changeContent's parameter is just the number of the button. Has no intrinsic association with the content -->
          <button id="intact_button1" class="btn" onclick="cateChangeContent(1)">Object Diversity</button>
          <button id="intact_button2" class="btn" onclick="cateChangeContent(2)">Language Complexity</button>
          <button id="intact_button3" class="btn" onclick="cateChangeContent(3)">Vision-Language Thinking</button>

          <div class="content has-text-justified">
            <p id="cate-text-content">
              Truly generalist policies require perceptual ability <b>beyond</b> the object distributions <b>encountered during training or fine-tuning</b>. 
              <br><br>
              In SimplerEnv, which assume the fine-tuning dataset is BridgeV2, all manipulation tasks are <code>Put {Source} on {Target}</code>. Therefore, We introduce <b>four</b> categories of <b>out-of-distribution objects</b> that resemble original objects in affordances/grasping difficulty.
              <br>
              <br><b>OOD Source:</b> Source object not present in BridgeV2, but target object is.
              <br><b>OOD Target:</b> Target object not present in BridgeV2, but source object is.
              <br><b>OOD Source + Target:</b> Both source and target objects are not present in BridgeV2.
              <br><b>OOD Relation:</b> Relation between objects is different from the training data. For example, if the training data has <code>Put {Source} on {Target}</code>, then the OOD relation can be <code>Put {Target} on {Source}</code>.
            </p>
            <center>
              <img id="cate-image-content" src="./static/images/object_vision_example.svg" style="width: 62vw;" />
            </center>
          </div>
        </center>

        <script>
          document.getElementById('intact_button1').classList.add('active');
          function cateChangeContent(buttonNumber) {
              const cateTextElement = document.getElementById('cate-text-content');
              const cateImageElement = document.getElementById('cate-image-content');
              
              document.getElementById('intact_button1').classList.remove('active');
              document.getElementById('intact_button2').classList.remove('active');
              document.getElementById('intact_button3').classList.remove('active');

              // Add 'active' class to the clicked button so that it will have a different color when its content is present
              document.getElementById('intact_button' + buttonNumber).classList.add('active');

              if (buttonNumber === 1) {
                  cateTextElement.innerHTML = `
                                          Truly generalist policies require perceptual ability <b>beyond</b> the object distributions <b>encountered during training or fine-tuning</b>.
                                          <br><br>
                                          In SimplerEnv, which assume the fine-tuning dataset is BridgeV2, all manipulation tasks are <code>Put {Source} on {Target}</code>. Therefore, We introduce <b>four</b> categories of <b>out-of-distribution objects</b> that resemble original objects in affordances/grasping difficulty.
                                          <br>
                                          <br><b>OOD Source:</b> Source object not present in BridgeV2, but target object is.
                                          <br><b>OOD Target:</b> Target object not present in BridgeV2, but source object is.
                                          <br><b>OOD Source + Target:</b> Both source and target objects are not present in BridgeV2.
                                          <br><b>OOD Relation:</b> Relation between objects is different from the training data. For example, if the training data has <code>Put {Source} on {Target}</code>, then the OOD relation can be <code>Put {Target} on {Source}</code>.`;
                  cateImageElement.classList.remove('hidden');
                  cateImageElement.src = "./static/images/object_vision_example.svg";
                  cateImageElement.style.width  = "62vw";
                  cateImageElement.style.height = "auto";
                  // imageElement.alt = "Image 1";
              } else if (buttonNumber === 2) {
                  cateTextElement.innerHTML = `
                                          To probe whether VLAs inherit the advanced <b>language generalization</b> abilities of their underlying VLMs, we augment the original SimplerEnv instructions with <b>three</b> types of complex <b>linguistic variations</b>.
                                          <br>
                                          <br><b>Language Action:</b> Paraphrase verbs to be compositional and less frequent than in BridgeV2. (e.g., <code>Put {Source} on {Target}</code> &#8594; <code>Pick up {Source} and lay on top of {Target}</code>).
                                          <br><b>Language Negation:</b> Add negation such as <code>not, don't</code> to irrelevant objects. (e.g., <code>Put {Source} on {Target}</code> &#8594; <code> Put {Source} on {Target}, not {Irrelevant}</code>).
                                          <br><b>Language Appearance:</b> Replace object with descriptive words. (e.g., <code>Put eggplant on {Target}</code> &#8594; <code>Put the purple object on {Source}</code>).`;
                  cateImageElement.classList.remove('hidden');
                  cateImageElement.src = "./static/images/language_complexity.svg";
                  cateImageElement.style.width  = "20vw";
                  cateImageElement.style.height = "auto";
                  // imageElement.alt = "Image 2";
              } else if (buttonNumber === 3) {
                  cateTextElement.innerHTML = `
                                          To be useful in the real world, a generalist policy should be able to operate in <b>visually clustered</b> environments and possess <b>commonsense</b>.
                                          <br><br>
                                          SimplerEnv focuses on minimalist scenes with no semantic ambiguity. We therefore add <b> three </b> types of advanced tasks that require visual-language thinking and commonsense.
                                          <br>
                                          <br><b>Object Distraction:</b> Introduce objects not relevant to the task.
                                          <br><b>Commonsense:</b> Modify instructions to require commonsense and reasoning (e.g., <code>Put carrot on {Target}</code> &#8594; <code> Put the vegetable that rabbits like on {Target}</code>).
                                          <br><b>Commonsense + Object Distraction:</b> Introduce distractor objects that needs commonsense to distinguish (e.g., Introduce an orange object for task <code>Put orange juice on {Target}</code>).`;
                  cateImageElement.classList.remove('hidden');
                  cateImageElement.src = "./static/images/object_vision_example.svg";
                  cateImageElement.style.width  = "62vw";
                  cateImageElement.style.height = "auto";
              }
          }
        </script>

      </div>
    </div>
  </div>
</section>

<hr>

<!-- Benchmarking Results -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Benchmarking Results</h2>
        <center>
          <!-- Here, the changeContent's parameter is just the number of the button. Has no intrinsic association with the content -->
          <button id="method_button1" class="btn" onclick="changeContent(1)">Intention-Action Gap</button>
          <button id="method_button2" class="btn" onclick="changeContent(2)">OOD Objects</button>
          <button id="method_button3" class="btn" onclick="changeContent(3)">Preserving Linguistic Capability</button>
          <button id="method_button4" class="btn" onclick="changeContent(4)">Preserving Vision-Language Thinking</button>

          <div class="content has-text-justified">
            <p id="text-content">
              All VLAs exhibit persistent <b>intention-action gaps</b>. They correctly interpret out-of-distribution objects or instructions, thanks to their pretrained VLM, but their execution accuracy still falls sharply.
            </p>
            <center>
              <img id="image-content" src="./static/images/radarmap.png" style="width: 62vw;" />
            </center>
          </div>
        </center>

        <script>
          document.getElementById('method_button1').classList.add('active');
          function changeContent(buttonNumber) {
              const textElement = document.getElementById('text-content');
              const imageElement = document.getElementById('image-content');
              
              document.getElementById('method_button1').classList.remove('active');
              document.getElementById('method_button2').classList.remove('active');
              document.getElementById('method_button3').classList.remove('active');
              document.getElementById('method_button4').classList.remove('active');
              // Add 'active' class to the clicked button so that it will have a different color when its content is present
              document.getElementById('method_button' + buttonNumber).classList.add('active');

              if (buttonNumber === 1) {
                  textElement.innerHTML = `
                                          All VLAs exhibit persistent <b>intention-action gaps</b>. They correctly interpret out-of-distribution objects or instructions, thanks to their pretrained VLM, but their execution accuracy still falls sharply.`;
                  imageElement.classList.remove('hidden');
                  imageElement.src = "./static/images/radarmap.png";
                  imageElement.style.width  = "62vw";
                  imageElement.style.height = "auto";
                  // imageElement.alt = "Image 1";
              } else if (buttonNumber === 2) {
                  textElement.innerHTML = `
                                          When faced with out-of-distribution objects, VLAs shows <b>robustness with intention</b>: They still knows which item to approach. However, they <b>struggle with execution</b> as the grasping often falls short.
                                          <br><br>
                                          Interestingly, even when the source is unchanged and the target is swapped for one of similar size and shape, which shouldn't raise difficulty, the grasp and task success rate can still fall sharply. We hypothesize this stems from the end-to-end nature of VLAs.`;
                  imageElement.classList.remove('hidden');
                  imageElement.src = "./static/images/ood_objects.svg";
                  // imageElement.style.width  = "20vw";
                  // imageElement.style.height = "auto";
                  // imageElement.alt = "Image 2";
              } else if (buttonNumber === 3) {
                  textElement.innerHTML = `
                                          VLAs suffer a <b>significant performance drop</b> on complex language instructions, even though their underlying VLMs handle such complexity well. 
                                          <br><br>
                                          Magma, using joint vision-language co-training, appears relatively robust, suggesting this approach helps VLAs retain their VLM's advanced linguistic capabilities.`;
                  imageElement.classList.remove('hidden');
                  imageElement.src = "./static/images/language_complexity_result.png";
                  // imageElement.style.width  = "62vw";
                  // imageElement.style.height = "auto";
              } else if (buttonNumber === 4) {
                  textElement.innerHTML = `
                                          Although the underlying VLMs often demonstrate strong vision-language reasoning, we observed that VLAs <b>struggle</b> with <b>commonsense</b> and <b>visual-language thinking</b>, especially in the presence of <b>distractor objects</b>.<br>
                                          <br>
                                          For example, when both <b>orange juice</b> and <b>orange</b> appear together, VLAs frequently confuse them, even though they succeed reliably when only one is present and the underlying VLM can easily tell them apart.`;
                  imageElement.classList.remove('hidden');
                  imageElement.src = "./static/images/distract.svg";
                  // imageElement.style.width  = "62vw";
                  // imageElement.style.height = "auto";
              }
          }
        </script>

      </div>
    </div>
  </div>
</section>

<hr>

<!-- BibTeX -->
<section class="section" id="BibTeX"> 
  <div class="container is-max-desktop content">
    <center>
    <h2 id="bibtexTitle" class="title">BibTeX</h2>
    <button id="copyButton" onclick="copyToClipboard()">
      <i class="fas fa-copy"></i>
    </button>
    <br>
    <pre style="display: inline-flex; text-align: left";><code id="bibtexInfo">
Coming Soon
      </code>
    </pre>
  </center>
  </div>
</section>
          
<!-- Acknowledgements   -->
<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    Chen Feng is the corresponding authors.
  </div>
</section>
          
<!-- Footer -->       
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.<br>
            This AI4CE template is created by <a href="https://irvingf7.github.io/">Irving Fang</a>.<br>
            This webpage template is originally from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
            This website is then inspired by the project page of <a href="https://cat3d.github.io/">CAT3D</a>, <a href="https://armlabstanford.github.io/touch-gs">Touch-GS</a> and <a href="https://baegwangbin.github.io/DSINE/">DSINE</a>.
          </p>
        </div>
      </div>
          </p>
        </div>
      </div>
  </div>
</footer>

</body>

</html>
